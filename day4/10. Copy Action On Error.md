// Create new stage
```sql
 CREATE OR REPLACE STAGE MANAGE_DB.external_stages.aws_stage_errorex
    url='s3://bucketsnowflakes4';
 ```
 ```sql
 // List files in stage
 LIST @MANAGE_DB.external_stages.aws_stage_errorex;
 
 ```
 The csv file contains text for int columns such as profit `'one hundred'`
 Type conversion error we will get it .

 ```sql
 // Create example table
 CREATE OR REPLACE TABLE OUR_FIRST_DB.PUBLIC.ORDERS_EX (
    ORDER_ID VARCHAR(30),
    AMOUNT INT,
    PROFIT INT,
    QUANTITY INT,
    CATEGORY VARCHAR(30),
    SUBCATEGORY VARCHAR(30));
 
 // Demonstrating error message
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX
    FROM @MANAGE_DB.external_stages.aws_stage_errorex
     file_format= (type = csv field_delimiter=',' skip_header=1)
     files = ('OrderDetails_error.csv');
```
![alt text](image-27.png)
 // Validating table is empty    
`SELECT * FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX  ;  `
    
```sql
  // Error handling using the ON_ERROR option
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX
    FROM @MANAGE_DB.external_stages.aws_stage_errorex
    file_format= (type = csv field_delimiter=',' skip_header=1)
    files = ('OrderDetails_error.csv')
    ON_ERROR = 'CONTINUE';
``` 
`ON_ERROR = 'CONTINUE'`

Keep loading good rows and skip any rows that error. The statement completes successfully, but some rows can be rejected and not inserted.

![alt text](image-28.png)
![alt text](image-29.png)
![alt text](image-30.png)

##  // Validating results and truncating table 
`SELECT * FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;`

`SELECT COUNT(*) FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;`

`TRUNCATE TABLE OUR_FIRST_DB.PUBLIC.ORDERS_EX;`

### Error handling using the ON_ERROR option = ABORT_STATEMENT (default)

```sql
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX
    FROM @MANAGE_DB.external_stages.aws_stage_errorex
    file_format= (type = csv field_delimiter=',' skip_header=1)
    files = ('OrderDetails_error.csv','OrderDetails_error2.csv')
    ON_ERROR = 'ABORT_STATEMENT';


  // Validating results and truncating table 
SELECT * FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;
SELECT COUNT(*) FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;

TRUNCATE TABLE OUR_FIRST_DB.PUBLIC.ORDERS_EX;
```
ON_ERROR = 'ABORT_STATEMENT' means strict, all-or-nothing loading:

If any row in any of the specified files causes a parsing/conversion/column-count error, Snowflake stops immediately and fails the entire COPY.

No rows are loaded/committed from any file; the target table remains unchanged.

Use it as a quality gate when you’d rather fix the data or file format than accept partial loads.

Quick contrasts:

**CONTINUE** → load good rows, skip bad rows.

**SKIP_FILE** → if a file has an error, skip that whole file but load others.
## // Error handling using the ON_ERROR option = SKIP_FILE
```sql
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX
    FROM @MANAGE_DB.external_stages.aws_stage_errorex
    file_format= (type = csv field_delimiter=',' skip_header=1)
    files = ('OrderDetails_error.csv','OrderDetails_error2.csv')
    ON_ERROR = 'SKIP_FILE';
    
    
  // Validating results and truncating table 
SELECT * FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;
SELECT COUNT(*) FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;

TRUNCATE TABLE OUR_FIRST_DB.PUBLIC.ORDERS_EX;    
```
- If `OrderDetails_error.csv` has a bad row (e.g., column-count mismatch, bad cast), **Snowflake skips that whole file** (0 rows loaded from it) and then **tries the next file**.  
- If `OrderDetails_error2.csv` has no errors, its **good rows load** normally.  
- If **both** files contain errors, **both are skipped** and **no data is loaded**.  
- Use this when you want **clean, file-level atomicity** (a “good file loads, bad file doesn’t”) but still want the **overall job to succeed** for the other files.  

![alt text](image-31.png)  

## // Error handling using the ON_ERROR option = SKIP_FILE_<number>
```sql
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX
    FROM @MANAGE_DB.external_stages.aws_stage_errorex
    file_format= (type = csv field_delimiter=',' skip_header=1)
    files = ('OrderDetails_error.csv','OrderDetails_error2.csv')
    ON_ERROR = 'SKIP_FILE_2';    
    
    
  // Validating results and truncating table 
SELECT * FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;
SELECT COUNT(*) FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;

TRUNCATE TABLE OUR_FIRST_DB.PUBLIC.ORDERS_EX;    
```
`ON_ERROR = 'SKIP_FILE_2'` means:

- If a file has **2 or more errors**, Snowflake **skips that entire file** (0 rows loaded from it) and moves to the next file.  
- If the file has **fewer than 2 errors**, only the bad rows are skipped, and the rest of the good rows from that file are loaded.  

So basically:  

**Threshold-based skip** — load partially if errors are below the threshold; skip the file entirely if errors meet or exceed the number.  

    
// Error handling using the ON_ERROR option = SKIP_FILE_<number>
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX
    FROM @MANAGE_DB.external_stages.aws_stage_errorex
    file_format= (type = csv field_delimiter=',' skip_header=1)
    files = ('OrderDetails_error.csv','OrderDetails_error2.csv')
    ON_ERROR = 'SKIP_FILE_3%'; 
  
  
SELECT * FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;


 CREATE OR REPLACE TABLE OUR_FIRST_DB.PUBLIC.ORDERS_EX (
    ORDER_ID VARCHAR(30),
    AMOUNT INT,
    PROFIT INT,
    QUANTITY INT,
    CATEGORY VARCHAR(30),
    SUBCATEGORY VARCHAR(30));




```sql
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX
    FROM @MANAGE_DB.external_stages.aws_stage_errorex
    file_format= (type = csv field_delimiter=',' skip_header=1)
    files = ('OrderDetails_error.csv','OrderDetails_error2.csv')
    ON_ERROR = SKIP_FILE_3 
    SIZE_LIMIT = 30;
```


